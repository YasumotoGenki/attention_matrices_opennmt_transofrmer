# attention_matrices_opennmt_transofrmer
This code will provide additional debug function to output attention matrices from all heads in all layers.

**Be careful, this code is only for transformer translation with OpenNMT**

**You cannot use this for any other purpose (training, rnn model, and so on)**





## Usage

The usage is described the next 2 files.

[0_training.ipynb] ()
[1_translation.ipynb] ()
